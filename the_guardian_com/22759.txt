Despite protests that "more than 20 hours of video [are] uploaded every minute worldwide" (YouTube urged to remove footage of radical cleric, 3 November), Google and YouTube are guilty already of gross neglect and irresponsibility. Instead of sloughing off responsibility to "community vigilance", Google should use its enormous multilingual machine and computational resources to flag automatically all posted YouTube content that contains a growing list of code words – known names and terms, in all languages – and immediately divert all suspect postings for human inspection before allowing them to be publicly viewable.Everyone is making monumental worldwide efforts in screening at airports, with real human time and energy and money involved, yet one enormous company, with the means to do automated computational screening of unprecedented power and pinpoint specificity – look how much ingenuity is put into screening shoppers' predilections – is not exercising its latent capacity on content with damage potential vastly exceeding any airport. A simple search on a prominent terrorist's name can retrieved over 5,000 videos. The postings from accredited news organisations could be hand-cleared easily. But there are plenty up there from the sage himself, advocating jihads and fatwas, with thousands of views and no user alerts. And before the reflex laissez-faire fatalists begin to whine about censorship, this is not about the right to speak or publish, but about the privilege of using one private company's global megaphone. Entrust porno-flagging to global users, but not terror-flagging.Stevan HarnadAmerican Scientist Open Access Forum