Stephen Hawking’s synthetic speech box is so fundamental to his persona that he reportedly refuses to upgrade to a more natural-sounding voice. But for the rest of the estimated 5,000 people with motor neurone disease in the UK – at least 80% of whom experience loss of speech – sounding like Stephen Hawking isn’t a particularly desirable prospect.That is why MND researchers are working to ensure patients can still use their own voices, even after they lose the ability to speak. Jason Liversidge, a 41-year-old father from Scarborough, was diagnosed with MND in 2013 and his speech is already impaired. Now specialists at the Anne Rowling clinic in Edinburgh are making him a synthetic voice with a Yorkshire accent, generated by dozens of speech donors from the Scarborough area – including his best friend Phil. “I just don’t want to be a programmed voice on a computer,” Liversidge recently told the BBC, describing his voice as “a form of identity”.Karen Pearce, a director of care at the MND Association, says people underestimate how central their speech patterns or catchphrases are to their identity. “I can’t imagine anything more important than being able to say to your wife, your husband or your children that you love them in your own voice,” she says, pointing to the case of an Irish man with MND who found that the off-the-peg selection of synthesised voices did not include an Irish male.“He either had to choose ‘Irish Mary’, or use a Scottish voice. So now he talks in a Scottish accent. That really has an impact on someone’s identity.”Liversidge is a lucky exception: he got involved with the University of Edinburgh’s Speak Unique project, a pilot programme collecting voice donations from every region, gender and age group in Scotland, which can theoretically be used to blend tailored voices resembling those of people with MND.The MND Association encourages people to bank their own voices as soon as possible after they are diagnosed, before the condition begins to affect their speech. Services such as CereVoice Me, ModelTalker and VocaliD invite patients to record several hundred phrases, from which they can generate an infinite selection of words and sentences using an iPad app controlled by the flick of a finger or the movement of an eye.Hawking’s current voice machine interface was custom-made by Intel in 2013, and is controlled by an infrared switch that he operates by twitching his cheek. But the voice itself is the same one he has had since 1986, when he got his first speech synthesiser. Even he can’t tell where it’s supposed to be from, writing on his website that his accent “has been described variously as Scandinavian, American or Scottish”.