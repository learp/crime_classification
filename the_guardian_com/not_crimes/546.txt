Just days after the National Highway Traffic Safety Administration launched an investigation into the fatal crash of a Tesla Model S driving in autopilot mode, a second Tesla using autopilot mode has been involved in a collision.Art gallery director Albert Scaglione told police he was driving in autopilot mode when his Tesla Model X crashed and rolled over on the Pennsylvania Turnpike around 100 miles east of Pittsburgh on 1 July. Scaglione and his artist son-in-law Tim Yane both survived without major injuries.Tesla said that it had no evidence to prove that the autopilot system was active during the second collision. “We received an automated alert from this vehicle on July 1 indicating airbag deployment, but logs containing detailed information on the state of the vehicle controls at the time of the collision were never received,” the company said in a statement.“This is consistent with damage of the severity reported in the press, which can cause the antenna to fail. Based on the information we have now, we have no reason to believe that autopilot had anything to do with this accident,” it said, adding that it had been unable to reach the vehicle’s ownerLidar: the self-driving technology that could help Tesla avoid another tragedy Whether or not Tesla’s autopilot malfunctioned, the news reinforces the question of whether car companies should release critical safety features to be beta-tested by consumers. The autopilot software, which Tesla is testing in a “public beta”, has been installed in all 70,000 of its cars since October 2014.“It is just not acceptable,” says prominent analyst Ferdinand Dudenhöffer, head of the Centre of Automotive Research at the University of Duisburg-Essen in Germany. “Cars are not toys and to launch a beta version of software with safety risks is not the way a company should care about the life of human beings. Just putting a sticker on it saying ‘customer is responsible’ is a nightmare.”Public beta testing of software is a practice typically used by technology companies to flush out bugs in products such as smartphone apps. It’s part of the Silicon Valley culture of getting the product into the hand of consumers as quickly as possible, and then monitoring and improving the product according to consumer feedback. Google credits some of its success to having a “never fail to fail” attitude, while until 2014 a common Facebook’s motto was “move fast and break things”. Just putting a sticker on it saying ‘customer is responsible’ is a nightmareFerdinand Dudenhöffer, analyst Tesla CEO Elon Musk has applied this approach to higher-risk environments, including space travel and electric cars. Speaking about his rocket company SpaceX, Musk has said: “Failure is an option here. If things are not failing, you are not innovating enough.”It’s an attitude at odds with the more cautious approach used by traditional car manufacturers outside of Silicon Valley, such as General Motors and Ford, who have restricted their semi-autonomous vehicles to test tracks.“The general impression among competitors is that Tesla was jumping the gun. It was doing what computer companies do – putting the product out there when it’s not even close to perfect. And then this fatality has happened,” said Sridhar Lakshmanan, engineering professor at the University of Michigan.      Facebook    Twitter    Pinterest   Joshua Brown, who was killed in a fatal car crash after he put his Tesla Model S in autopilot mode. Photograph: FacebookAutomotive industry analyst John McElroy agrees. “Traditional car manufacturers would never introduce a technology like this without it being fully tested,” he said. “Beta testing with consumers is a very bad idea when it comes to anything related to automotive safety.”McElroy recognises that Tesla warned its owners that autopilot was a beta system, but says that the company then “played it up as if it was quite developed”. Elon Musk's self-driving evangelism masks risk of Tesla autopilot, experts say In January Elon Musk stated that Tesla would be in a position to launch fully autonomous cars within two years. “I think we have all the pieces, and it’s just about refining those pieces, putting them in place, and making sure they work across a huge number of environments – and then we’re done,” Musk told Fortune. “It’s a much easier problem than people think it is.”Dudenhöffer believes that this gung-ho attitude is likely to damage public trust in driverless technology. “We all know that self-driving technology will be the most important innovation from the last 100 years. It will reduce accidents and fatalities dramatically, so we should do everything to make sure people can trust it,” he said.“Tesla did it the other way around. It will now be more difficult to convince customers to step into [driverless cars],” he added.