Facebook is the internet company accused by the intelligence and security committee of failing to pass on information which could have prevented the murder of Lee Rigby, the Guardian understands.The ISC investigation found that one of Rigby’s killers, Michael Adebowale, conducted an online exchange detailing his desire to murder a soldier “in the most graphic and emotive manner” with a known terrorist, five months before the attack, yet did not directly name the company concerned.“The party which could have made a difference was the company on whose platform the exchange took place,” states the report. “However, this company does not appear to regard itself as under any obligation to ensure that its systems identify such exchanges, or to take action or notify the authorities when its communications services appear to be used by terrorists.”“There is therefore a risk that, however unintentionally, it provides a safe haven for terrorists to communicate within,” it states.The report does not name which US tech service Adebowale used, but at various points the 191-page report mentions Apple, BlackBerry, Facebook, Google, Microsoft, Twitter and Yahoo when giving examples of monitoring procedures.The Guardian understands the company is Facebook. The report details 11 accounts run by Adebowale, with seven of those disabled by the company concerned and one closed by Adebowale himself.The ISC’s report says that the technology company closed the accounts in an automated manner for violation of the company’s terms of service. Two accounts were closed for non-terrorism related activities, but the other five were disabled for terrorism-associated reasons, including one for being part of terrorist groups.While no technology company would comment on the report to the Guardian, it is known that the posts were made in a private manner that wasn’t indexed by a search engine, that the accounts could be members of groups and that the company has automated systems for detecting and closing accounts for breach of terms of service.Facebook stands out amongst internet companies for proactively monitoring its platform to look for and remove content which raises concerns about terrorism and child safety issues. But the vast majority of moderation on Facebook is reactive, relying on reports from members of the public or on automated tools. Unlike the other internet companies consulted by the ISC, Facebook’s monitoring arrangements are heavily redacted in the resulting report.Facebook did not respond to requests for comment from the Guardian, nor did it respond when directly asked if it was the subject of the ISC’s report.No other technology company would comment on the report to the Guardian on the record.